{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Amanda Ades\n",
    "\n",
    "Nome: Beni Kracochansky\n",
    "\n",
    "Nome: Gabriel Kabbani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, gostariamos de explicitar que durante a nossa análise, os números \"0,1,2\" representam, respectivamente, elogios, críticas, e irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Tesla'\n",
    "\n",
    "#aumentamos a quantidade de mensagens devido a quantidade de retweets.\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 950\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 600\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets= pd.ExcelFile('Tesla.xlsx')\n",
    "treino= pd.read_excel(tweets, sheet_name='Treinamento')\n",
    "teste= pd.read_excel(tweets, sheet_name='Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amanda Ades\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Amanda Ades\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Limpando a base de dados:\n",
    "\n",
    "def limpador(tweet):\n",
    "    retirar=[',',';','\\n','...','......','***','.','-','|','?','!',':','[',']','(',')','\"',\"'\",'&','#'] #verificar se faltam outros.\n",
    "    tweet=str(tweet)\n",
    "    tweet=tweet.split()\n",
    "    lista=['@','https://']\n",
    "    for i in tweet:\n",
    "        i=i.lower()\n",
    "    palavras=[]\n",
    "    for palavra in tweet:\n",
    "        if len(palavra)>0:\n",
    "            if palavra[0]==lista[0]:\n",
    "                pass\n",
    "            if len(palavra)>7:\n",
    "                if palavra[:8]==lista[1]:\n",
    "                    pass\n",
    "            else:\n",
    "                for item in retirar:\n",
    "                    palavra=palavra.strip(item)\n",
    "                palavras.append(palavra)\n",
    "    return \" \".join(palavras)\n",
    "\n",
    "tweets=[]\n",
    "for tweet in treino['Treinamento']: #limpando todos os tweets da sheet 'Treinamento', e adicionando eles a uma lista.\n",
    "        tweets.append(limpador(tweet))\n",
    "for e in range (len(treino['Treinamento'])): #limpa o dataframe com os dados obtidos acima.\n",
    "    if tweets[e][:2] == \"rt\": #removendo retweets.\n",
    "        treino['Classificacao'][e]=3 #colocando um número diferente para que os retweets não sejam utilizados na analise. Destes, os @ não serão retirados, mas isso não impacta a análise pois não serão utilizados nela.\n",
    "    else:\n",
    "        treino['Treinamento'][e]=tweets[e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elogios: 299\n",
      "Total de críticas: 123\n",
      "Total de irrelevantes: 94\n",
      "Total: 516\n"
     ]
    }
   ],
   "source": [
    "Elogios,Críticas,Irrelevantes,Retweets=treino['Classificacao'].value_counts()\n",
    "Total=Elogios+Críticas+Irrelevantes\n",
    "\n",
    "print('Total de elogios: {0}\\nTotal de críticas: {1}\\nTotal de irrelevantes: {2}\\nTotal: {3}'.format(Elogios,Críticas,Irrelevantes,Total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Número de Elogios</th>\n",
       "      <th>Número de Críticas</th>\n",
       "      <th>Número de Irrelevantes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tesla</th>\n",
       "      <td>105.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>44.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>54.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>60.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>38.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Número de Elogios  Número de Críticas  Número de Irrelevantes\n",
       "tesla              105.0                80.0                   200.0\n",
       "o                   44.0                21.0                   141.0\n",
       "de                  54.0                45.0                   138.0\n",
       "a                   60.0                28.0                   136.0\n",
       "e                   38.0                29.0                   129.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E=treino[treino['Classificacao']==0]\n",
    "C=treino[treino['Classificacao']==1]\n",
    "I=treino[treino['Classificacao']==2]\n",
    "palavras_separadas={}\n",
    "i=0\n",
    "\n",
    "for tipo in [E,C,I]: #separa as palavras de cada tipo de classificação em uma lista. Essa lista será o valor do nome do tipo de classificação no dicionário.\n",
    "    if i==0:\n",
    "        nome='Elogios'\n",
    "    if i==1:\n",
    "        nome='Críticas'\n",
    "    if i==2:\n",
    "        nome='Irrelevantes'\n",
    "    lista=[]\n",
    "    for tweet in tipo['Treinamento']:\n",
    "        palavras=tweet.split()\n",
    "        lista.extend(palavras)\n",
    "    palavras_separadas[nome]=lista\n",
    "    i+=1\n",
    "\n",
    "\n",
    "palE=pd.DataFrame(data=palavras_separadas['Elogios'])\n",
    "palE=palE[0].value_counts().to_frame()\n",
    "palE.columns=['Número de Elogios']\n",
    "\n",
    "\n",
    "palC=pd.DataFrame(data=palavras_separadas['Críticas'])\n",
    "palC=palC[0].value_counts().to_frame()\n",
    "palC.columns=['Número de Críticas']\n",
    "\n",
    "\n",
    "\n",
    "palI=pd.DataFrame(data=palavras_separadas['Irrelevantes'])\n",
    "palI=palI[0].value_counts().to_frame()\n",
    "palI.columns=['Número de Irrelevantes']\n",
    "\n",
    "\n",
    "pal=palE.join(palC, how='outer').fillna(0)\n",
    "pal=pal.join(palI, how='outer').fillna(0)\n",
    "pal.sort_values(by='Número de Irrelevantes', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador(tweet):\n",
    "    PE=pal['Número de Elogios']\n",
    "    somaE=sum(PE)\n",
    "    probE=1\n",
    "    PC=pal['Número de Críticas']\n",
    "    somaC=sum(PC)\n",
    "    probC=1\n",
    "    PI=pal['Número de Irrelevantes']\n",
    "    somaI=sum(PI)\n",
    "    probI=1\n",
    "    tot=len(pal)\n",
    "    \n",
    "    for palavra in limpador(tweet):\n",
    "        if palavra in pal.index:\n",
    "            probE*=((PE[palavra]+1)/(somaE+tot)) #Laplace\n",
    "            probC*=((PC[palavra]+1)/(somaC+tot))\n",
    "            probI*=((PI[palavra]+1)/(somaI+tot))\n",
    "        else:\n",
    "            probE*=(1/(somaE+tot)) #Laplace\n",
    "            probC*=(1/(somaC+tot))\n",
    "            probI*=(1/(somaI+tot))\n",
    "            \n",
    "    probE*=(Elogios/Total)\n",
    "    probC*=(Críticas/Total)\n",
    "    probI*=(Irrelevantes/Total)\n",
    "    \n",
    "    probMax=0\n",
    "    resultado=0\n",
    "    \n",
    "    for e in [probE,probC,probI]:\n",
    "        if e==probE:\n",
    "            a='0'#elogio\n",
    "        if e==probC:\n",
    "            a='1'#critica\n",
    "        if e==probI:\n",
    "            a='2'#irrelevante\n",
    "        if e>probMax:\n",
    "            probMax=e\n",
    "            resultado=a\n",
    "        \n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    221\n",
       "0     81\n",
       "1     48\n",
       "Name: Classificacao, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste['Classificacao'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elogio verdadeiro:\n",
      "Quantidade:33\n",
      "Porcentagem do total de elogios:21.15%\n",
      "\n",
      "\n",
      "Elogio falso:\n",
      "Quantidade:123\n",
      "Porcentagem do total de elogios:78.85%\n",
      "\n",
      "\n",
      "Crítica verdadeira:\n",
      "Quantidade:11\n",
      "Porcentagem do total de críticas:9.73%\n",
      "\n",
      "\n",
      "Crítica falsa:\n",
      "Quantidade:102\n",
      "Porcentagem do total de críticas:90.27%\n",
      "\n",
      "\n",
      "Irrelevante verdadeiro:\n",
      "Quantidade:50\n",
      "Porcentagem do total de irrelevantes:61.73%\n",
      "\n",
      "\n",
      "Irrelevante falso:\n",
      "Quantidade:31\n",
      "Porcentagem do total de irrelevantes:38.27%\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Porcentagem de erro do classificador: 69.13%\n",
      "\n",
      "Porcentagem de acerto do classificador: 30.87%\n"
     ]
    }
   ],
   "source": [
    "true_elogio=0\n",
    "false_elogio=0\n",
    "true_critica=0\n",
    "false_critica=0\n",
    "true_irrelevante=0\n",
    "false_irrelevante=0\n",
    "\n",
    "for e in teste.index:\n",
    "    if int(classificador(limpador(teste['Teste'][e]))) == int(teste['Classificacao'][e]):\n",
    "        if int(teste['Classificacao'][e])==0:\n",
    "            true_elogio+=1\n",
    "        elif int(teste['Classificacao'][e])==1:\n",
    "            true_critica+=1\n",
    "        elif int(teste['Classificacao'][e])==2:\n",
    "            true_irrelevante+=1\n",
    "    elif int(classificador(limpador(teste['Teste'][e]))) != int(teste['Classificacao'][e]):\n",
    "        if int(classificador(teste['Teste'][e]))==0:\n",
    "            false_elogio+=1\n",
    "        elif int(classificador(teste['Teste'][e]))==1:\n",
    "            false_critica+=1\n",
    "        elif int(classificador(teste['Teste'][e]))==2:\n",
    "            false_irrelevante+=1\n",
    "            \n",
    "\n",
    "totale=true_elogio+false_elogio\n",
    "totalc=true_critica+false_critica\n",
    "totali=true_irrelevante+false_irrelevante\n",
    "\n",
    "FC=false_critica*100/totalc\n",
    "FE=false_elogio*100/totale\n",
    "FI=false_irrelevante*100/totali\n",
    "\n",
    "\n",
    "print(\"Elogio verdadeiro:\\nQuantidade:{0}\\nPorcentagem do total de elogios:{1:.2f}%\".format(true_elogio,true_elogio*100/totale))\n",
    "print()\n",
    "print()\n",
    "print(\"Elogio falso:\\nQuantidade:{0}\\nPorcentagem do total de elogios:{1:.2f}%\".format(false_elogio,FE))\n",
    "print()\n",
    "print()\n",
    "print(\"Crítica verdadeira:\\nQuantidade:{0}\\nPorcentagem do total de críticas:{1:.2f}%\".format(true_critica,true_critica*100/totalc))\n",
    "print()\n",
    "print()\n",
    "print(\"Crítica falsa:\\nQuantidade:{0}\\nPorcentagem do total de críticas:{1:.2f}%\".format(false_critica,FC))\n",
    "print()\n",
    "print()\n",
    "print(\"Irrelevante verdadeiro:\\nQuantidade:{0}\\nPorcentagem do total de irrelevantes:{1:.2f}%\".format(true_irrelevante,true_irrelevante*100/totali))\n",
    "print()\n",
    "print()\n",
    "print(\"Irrelevante falso:\\nQuantidade:{0}\\nPorcentagem do total de irrelevantes:{1:.2f}%\".format(false_irrelevante,FI))\n",
    "print()\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "print(\"Porcentagem de erro do classificador: {0:.2f}%\".format(FE/3+FC/3+FI/3))\n",
    "print()\n",
    "print(\"Porcentagem de acerto do classificador: {0:.2f}%\".format(100-(FE/3+FC/3+FI/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TweepError",
     "evalue": "Twitter error response: status code = 429",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-e5cf34a77ab4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmsgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproduto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"extended\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mmsgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;31m# Reached end of current page, get the next page...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__self__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;31m# Parse the response payload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTweepError\u001b[0m: Twitter error response: status code = 429"
     ]
    }
   ],
   "source": [
    "api = tweepy.API(auth)\n",
    "while (True):\n",
    "    produto = 'Tesla'\n",
    "    lang = 'pt'\n",
    "    n=200\n",
    "    i = 1\n",
    "    msgs = []\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "    shuffle(msgs)\n",
    "\n",
    "\n",
    "    #Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "    live = pd.DataFrame({'Ao vivo' : pd.Series(msgs)})\n",
    "    lista=[]\n",
    "    for tweet in live['Ao vivo']:\n",
    "        lista.append(int(classificador(limpador(tweet))))\n",
    "    porcentagem_elogio=(lista.count(0))*100/len(lista)\n",
    "    porcentagem_critica=(lista.count(1))*100/len(lista)\n",
    "    porcentagem_irrelevante=(lista.count(2))*100/len(lista)\n",
    "    \n",
    "    print('Porcentagem de elogios, com relação ao total de tweets: {0:.2f}%'.format(porcentagem_elogio))\n",
    "    print('Porcentagem de criticas, com relação ao total de tweets: {0:.2f}%'.format(porcentagem_critica))\n",
    "    print('Porcentagem de irrelevantes, com relação ao total de tweets: {0:.2f}%'.format(porcentagem_irrelevante))\n",
    "    sleep(60**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criticar o \"nao gosto\" que vai ficar \"nao\" e \"gosto\", dificultando a analise e piorando o classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ao vivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sobre o carro tesla branco que apareceu nas ul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @laurencombr: ig story | lauren publicou #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @barnior: esta lâmpada usa levitação magnét...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#agilzinha #tesla corra e invista! https://t.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@edukof @tesla aí sim....  heee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @smith_hays: o projeto que será votado no s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>olha como vai https://t.co/gwpe9oa638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@edukof @tesla agora vai ser muuito melhor fic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rt @nathpuneet: boom v10 #tesla #eap #model3 #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ex-executivo da tesla abre negócio no brasil e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@edukof @tesla sei lá oq ta escrito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rt @laurmilaupdates: lauren postou no instagra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@edukof @tesla pelo que eu soube, só vai dar p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>é uma simples pilha, mas pode durar 20 anos e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rt @laurmilaupdates: lauren postou no instagra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@edukof @tesla que bom pa voce fico feliz por ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\" uma das minhas partes favoritas de ter um te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>análise certeira do mercado de energia no bras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>felizmente a tesla está na dianteira tecnológi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@sinapsepodcast o que tesla via nos números 3,6,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@alexroy144 @kotaku @lukeplunkett @a_w_gordon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>apple = tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rt @laurmilaupdates: lauren postou no instagra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@momentsbrasil #foigolpe todo munfo já sabia!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@hemeterio @fellipec eu queria ter um. com mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>@gu_rebel @climaotahiti a tesla nunca iriam co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>nem quando eu tava no cursinho, ficando no tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>grande atualização de software tesla v10 traz ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>rt @laurmilaupdates: lauren postou no instagra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>rt @edukof: minhas viagens de carro nunca mais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>rt @laurencombr: ig story | lauren publicou #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>noivo usa #teslacam para gravar seu pedido de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>rt @laurmilaupdates: lauren postou no instagra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>rt @miamicut: imagina uma foto da lauren com r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>@tesla meta af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>puto como é que em pleno 2019 existem pessoas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>@mgust4v0 @h1saiadamatrix @alan_za @ddermarau ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>@edukof @tesla aí já eh demais pra mim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>@tesla esse já foi um paraíso que eu conheci e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>rt @laurmilaupdates: lauren postou no instagra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>acabei de ler que uma revista alemã que disse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>rt @miamicut: imagina uma foto da lauren com r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>peguei a referência\\n\\nsó quem viveu sabe http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>rt @laurencombr: ig story | lauren publicou #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>jovens de hoje em dia:\\n\\n- sexo \\n- bebidas \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>rt @laurencombr: ig story | lauren publicou #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>rt @mafialaurenjbr: tradução: \"uma das minhas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rt @mahrcel: emoção de brasileiro ao viajar pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>rt @laurmilaupdates: lauren postou no instagra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Ao vivo\n",
       "0    sobre o carro tesla branco que apareceu nas ul...\n",
       "1    rt @laurencombr: ig story | lauren publicou #9...\n",
       "2    rt @barnior: esta lâmpada usa levitação magnét...\n",
       "3    #agilzinha #tesla corra e invista! https://t.c...\n",
       "4                      @edukof @tesla aí sim....  heee\n",
       "5    rt @smith_hays: o projeto que será votado no s...\n",
       "6    rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "7                olha como vai https://t.co/gwpe9oa638\n",
       "8    @edukof @tesla agora vai ser muuito melhor fic...\n",
       "9    rt @nathpuneet: boom v10 #tesla #eap #model3 #...\n",
       "10   ex-executivo da tesla abre negócio no brasil e...\n",
       "11                 @edukof @tesla sei lá oq ta escrito\n",
       "12   rt @laurmilaupdates: lauren postou no instagra...\n",
       "13   @edukof @tesla pelo que eu soube, só vai dar p...\n",
       "14   é uma simples pilha, mas pode durar 20 anos e ...\n",
       "15   rt @laurmilaupdates: lauren postou no instagra...\n",
       "16   @edukof @tesla que bom pa voce fico feliz por ...\n",
       "17   \" uma das minhas partes favoritas de ter um te...\n",
       "18   rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "19   análise certeira do mercado de energia no bras...\n",
       "20   felizmente a tesla está na dianteira tecnológi...\n",
       "21   rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "22   @sinapsepodcast o que tesla via nos números 3,6,9\n",
       "23   @alexroy144 @kotaku @lukeplunkett @a_w_gordon ...\n",
       "24                                       apple = tesla\n",
       "25   rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "26   rt @laurmilaupdates: lauren postou no instagra...\n",
       "27   rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "28       @momentsbrasil #foigolpe todo munfo já sabia!\n",
       "29   @hemeterio @fellipec eu queria ter um. com mot...\n",
       "..                                                 ...\n",
       "170  rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "171  @gu_rebel @climaotahiti a tesla nunca iriam co...\n",
       "172  nem quando eu tava no cursinho, ficando no tes...\n",
       "173  rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "174  grande atualização de software tesla v10 traz ...\n",
       "175  rt @laurmilaupdates: lauren postou no instagra...\n",
       "176  rt @edukof: minhas viagens de carro nunca mais...\n",
       "177  rt @laurencombr: ig story | lauren publicou #9...\n",
       "178  rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "179  rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "180  noivo usa #teslacam para gravar seu pedido de ...\n",
       "181  rt @laurmilaupdates: lauren postou no instagra...\n",
       "182  rt @miamicut: imagina uma foto da lauren com r...\n",
       "183                                     @tesla meta af\n",
       "184  puto como é que em pleno 2019 existem pessoas ...\n",
       "185  rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "186  @mgust4v0 @h1saiadamatrix @alan_za @ddermarau ...\n",
       "187  rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "188             @edukof @tesla aí já eh demais pra mim\n",
       "189  @tesla esse já foi um paraíso que eu conheci e...\n",
       "190  rt @laurmilaupdates: lauren postou no instagra...\n",
       "191  acabei de ler que uma revista alemã que disse ...\n",
       "192  rt @miamicut: imagina uma foto da lauren com r...\n",
       "193  peguei a referência\\n\\nsó quem viveu sabe http...\n",
       "194  rt @laurencombr: ig story | lauren publicou #9...\n",
       "195  jovens de hoje em dia:\\n\\n- sexo \\n- bebidas \\...\n",
       "196  rt @laurencombr: ig story | lauren publicou #9...\n",
       "197  rt @mafialaurenjbr: tradução: \"uma das minhas ...\n",
       "198  rt @mahrcel: emoção de brasileiro ao viajar pr...\n",
       "199  rt @laurmilaupdates: lauren postou no instagra...\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
