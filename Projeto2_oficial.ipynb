{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Amanda Ades\n",
    "\n",
    "Nome: Beni Kracochansky\n",
    "\n",
    "Nome: Gabriel Kabbani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Tesla'\n",
    "\n",
    "#aumentamos a quantidade de mensagens devido a quantidade de retweets.\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 950\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 600\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets= pd.ExcelFile('Tesla.xlsx')\n",
    "treino= pd.read_excel(tweets, sheet_name='Treinamento')\n",
    "teste= pd.read_excel(tweets, sheet_name='Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@tesla eu sou mais o uno</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>um tesla pra barrar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ate dava cop se fosse ganda fan eu tou a poupa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @millylacombe: falta alguém perguntar: \"gle...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>silva gt verrati gt kdb gt pogba</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>taycan foi lançado esta semana será um bom par...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>app da tesla esteve em baixo mas não para entr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt @gizmodobr: vários donos de veículos da emp...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a tesla</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>os cara foram de nikola tesla a teoria da terr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificacao\n",
       "0                           @tesla eu sou mais o uno              1\n",
       "1                                um tesla pra barrar              2\n",
       "2  ate dava cop se fosse ganda fan eu tou a poupa...              2\n",
       "3  rt @millylacombe: falta alguém perguntar: \"gle...              3\n",
       "4                   silva gt verrati gt kdb gt pogba              2\n",
       "5  taycan foi lançado esta semana será um bom par...              0\n",
       "6  app da tesla esteve em baixo mas não para entr...              1\n",
       "7  rt @gizmodobr: vários donos de veículos da emp...              3\n",
       "8                                            a tesla              2\n",
       "9  os cara foram de nikola tesla a teoria da terr...              2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limpando a base de dados:\n",
    "\n",
    "def limpador(tweet):\n",
    "    retirar=[',',';','\\n','...','......','***','.','-','|','?','!',':','[',']','(',')','\"',\"'\",'&','#'] #verificar se faltam outros.\n",
    "    tweet=str(tweet)\n",
    "    tweet=tweet.split()\n",
    "    lista=['@','https://']\n",
    "    for i in tweet:\n",
    "        i=i.lower()\n",
    "    palavras=[]\n",
    "    for palavra in tweet:\n",
    "        if len(palavra)>0:\n",
    "            if palavra[0]==lista[0]:\n",
    "                pass\n",
    "            if len(palavra)>7:\n",
    "                if palavra[:8]==lista[1]:\n",
    "                    pass\n",
    "            else:\n",
    "                for item in retirar:\n",
    "                    palavra=palavra.strip(item)\n",
    "                palavras.append(palavra)\n",
    "    return \" \".join(palavras)\n",
    "\n",
    "tweets=[]\n",
    "for tweet in treino['Treinamento']: #limpando todos os tweets da sheet 'Treinamento', e adicionando eles a uma lista.\n",
    "        tweets.append(limpador(tweet))\n",
    "for e in range (len(treino['Treinamento'])): #limpa o dataframe com os dados obtidos acima.\n",
    "    if tweets[e][:2] == \"rt\": #removendo retweets.\n",
    "        treino['Classificacao'][e]=3 #colocando um número diferente para que os retweets não sejam utilizados na analise.\n",
    "    else:\n",
    "        treino['Treinamento'][e]=tweets[e]\n",
    "\n",
    "treino.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elogios: 299\n",
      "Total de críticas: 123\n",
      "Total de irrelevantes: 94\n",
      "Total: 516\n"
     ]
    }
   ],
   "source": [
    "Elogios,Críticas,Irrelevantes,Retweets=treino['Classificacao'].value_counts()\n",
    "Total=Elogios+Críticas+Irrelevantes\n",
    "\n",
    "print('Total de elogios: {0}\\nTotal de críticas: {1}\\nTotal de irrelevantes: {2}\\nTotal: {3}'.format(Elogios,Críticas,Irrelevantes,Total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E=treino[treino['Classificacao']==0]\n",
    "C=treino[treino['Classificacao']==1]\n",
    "I=treino[treino['Classificacao']==2]\n",
    "palavras_separadas={}\n",
    "i=0\n",
    "\n",
    "for tipo in [E,C,I]: #separa as palavras de cada tipo de classificação em uma lista. Essa lista será o valor do nome do tipo de classificação no dicionário.\n",
    "    if i==0:\n",
    "        nome='Elogios'\n",
    "    if i==1:\n",
    "        nome='Críticas'\n",
    "    if i==2:\n",
    "        nome='Irrelevantes'\n",
    "    lista=[]\n",
    "    for tweet in tipo['Treinamento']:\n",
    "        palavras=tweet.split()\n",
    "        lista.extend(palavras)\n",
    "    palavras_separadas[nome]=lista\n",
    "    i+=1\n",
    "\n",
    "\n",
    "palE=pd.DataFrame(data=palavras_separadas['Elogios'])\n",
    "palE=palE[0].value_counts().to_frame()\n",
    "palE.columns=['Número de Elogios']\n",
    "\n",
    "\n",
    "palC=pd.DataFrame(data=palavras_separadas['Críticas'])\n",
    "palC=palC[0].value_counts().to_frame()\n",
    "palC.columns=['Número de Críticas']\n",
    "\n",
    "\n",
    "\n",
    "palI=pd.DataFrame(data=palavras_separadas['Irrelevantes'])\n",
    "palI=palI[0].value_counts().to_frame()\n",
    "palI.columns=['Número de Irrelevantes']\n",
    "\n",
    "\n",
    "pal=palE.join(palC, how='outer').fillna(0)\n",
    "pal=pal.join(palI, how='outer').fillna(0)\n",
    "pal.sort_values(by='Número de Irrelevantes', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificar(tweet):\n",
    "    PE=pal['Número de Elogios']\n",
    "    somaE=sum(PE)\n",
    "    probE=1\n",
    "    PC=pal['Número de Críticas']\n",
    "    somaC=sum(PC)\n",
    "    probC=1\n",
    "    PI=pal['Número de Irrelevantes']\n",
    "    somaI=sum(PI)\n",
    "    probI=1\n",
    "    tot=len(pal)\n",
    "    \n",
    "    for palavra in limpador(tweet):\n",
    "        if palavra in pal.index:\n",
    "            probE*=((PE[i]+1)/(somaE+tot)) #ou eu divido por somaE +soma C...., ou soh pelo total\n",
    "            probC*=((PC[i]+1)/(somaC+tot))\n",
    "            probI*=((PI[i]+1)/(somaI+tot))\n",
    "        else:\n",
    "            probE*=(1/(somaE+tot)) #ou soh por 1? ou tenq usar laplace\n",
    "            probC*=(1/(somaC+tot))\n",
    "            probI*=(1/(somaI+tot))\n",
    "            \n",
    "    probE*=(Elogios/Total)\n",
    "    probC*=(Críticas/Total)\n",
    "    probI*=(Irrelevantes/Total)\n",
    "    \n",
    "    probMax=0\n",
    "    resultado=0\n",
    "    \n",
    "    for e in [probE,probC,probI]:\n",
    "        if e==probE:\n",
    "            a='Elogio'\n",
    "        if e==probC:\n",
    "            a='Crítica'\n",
    "        if e==probI:\n",
    "            a='Irrelevante'\n",
    "        if e>probMax:\n",
    "            probMax=e\n",
    "            resultado=a\n",
    "        \n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tirar os retweets denovo, mas p/ testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
