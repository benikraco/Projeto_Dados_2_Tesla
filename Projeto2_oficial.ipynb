{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Amanda Ades\n",
    "\n",
    "Nome: Beni Kracochansky\n",
    "\n",
    "Nome: Gabriel Kabbani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'auth.pass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-1b0f116798ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#leitura do arquivo no formato JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auth.pass'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auth.pass'"
     ]
    }
   ],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Tesla'\n",
    "\n",
    "#aumentamos a quantidade de mensagens devido a quantidade de retweets.\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 950\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 600\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets= pd.ExcelFile('Tesla.xlsx')\n",
    "treino= pd.read_excel(tweets, sheet_name='Treinamento')\n",
    "teste= pd.read_excel(tweets, sheet_name='Teste')\n",
    "\n",
    "#FAZER O GITIGNORE DO AUTH PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando a base de dados:\n",
    "\n",
    "def limpador(tweet):\n",
    "    retirar=[',',';','\\n','...','***','.','-','|','?','!',':','[',']','(',')','\"',\"'\",'&','#'] #verificar se faltam outros.\n",
    "    tweet=str(tweet)\n",
    "    tweet=tweet.split()\n",
    "    lista=['@','https://']\n",
    "    for i in tweet:\n",
    "        i=i.lower()\n",
    "    palavras=[]\n",
    "    for palavra in tweet:\n",
    "        if len(palavra)>0:\n",
    "            for item in retirar:\n",
    "                palavra.strip(item) #NAO ESTA REMOVENDO\n",
    "            if palavra[0]==lista[0]:\n",
    "                pass\n",
    "            if len(palavra)>7:\n",
    "                if palavra[:8]==lista[1]:\n",
    "                    pass\n",
    "            else:\n",
    "                palavras.append(palavra)\n",
    "    return \" \".join(palavras)\n",
    "\n",
    "tweets=[]\n",
    "for tweet in treino['Treinamento']: #limpando todos os tweets da sheet 'Treinamento', e adicionando eles a uma lista.\n",
    "        tweets.append(limpador(tweet))\n",
    "for e in range (len(treino['Treinamento'])): #limpa o dataframe com os dados obtidos acima.\n",
    "    if tweets[e][0:1] == \"rt\": #removendo retweets. n ta indo pcausa dos espacos\n",
    "        treino.drop(treino.index[e])#NAO ESTA DROPPING\n",
    "    else:\n",
    "        treino['Treinamento'][e]=tweets[e] \n",
    "        \n",
    "treino['Treinamento'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elogios: 335\n",
      "Total de críticas: 154\n",
      "Total de irrelevantes: 111\n",
      "Total: 600\n"
     ]
    }
   ],
   "source": [
    "Elogios,Críticas,Irrelevantes=treino['Classificacao'].value_counts()\n",
    "Total=Elogios+Críticas+Irrelevantes\n",
    "\n",
    "print('Total de elogios: {0}\\nTotal de críticas: {1}\\nTotal de irrelevantes: {2}\\nTotal: {3}'.format(Elogios,Críticas,Irrelevantes,Total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Número de Elogios</th>\n",
       "      <th>Número de Críticas</th>\n",
       "      <th>Número de Irrelevantes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>57.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tesla</th>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>65.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>69.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>48.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Número de Elogios  Número de Críticas  Número de Irrelevantes\n",
       "o                   57.0                25.0                   168.0\n",
       "tesla               91.0                91.0                   163.0\n",
       "de                  65.0                70.0                   151.0\n",
       "a                   69.0                29.0                   147.0\n",
       "e                   48.0                29.0                   144.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E=treino[treino['Classificacao']==0]\n",
    "C=treino[treino['Classificacao']==1]\n",
    "I=treino[treino['Classificacao']==2]\n",
    "palavras_separadas={}\n",
    "i=0\n",
    "\n",
    "for tipo in [E,C,I]: #separa as palavras de cada tipo de classificação em uma lista. Essa lista será o valor do nome do tipo de classificação no dicionário.\n",
    "    if i==0:\n",
    "        nome='Elogios'\n",
    "    if i==1:\n",
    "        nome='Críticas'\n",
    "    if i==2:\n",
    "        nome='Irrelevantes'\n",
    "    lista=[]\n",
    "    for tweet in tipo['Treinamento']:\n",
    "        palavras=tweet.split()\n",
    "        lista.extend(palavras)\n",
    "    palavras_separadas[nome]=lista\n",
    "    i+=1\n",
    "\n",
    "\n",
    "palE=pd.DataFrame(data=palavras_separadas['Elogios'])\n",
    "palE=palE[0].value_counts().to_frame()\n",
    "palE.columns=['Número de Elogios']\n",
    "\n",
    "\n",
    "palC=pd.DataFrame(data=palavras_separadas['Críticas'])\n",
    "palC=palC[0].value_counts().to_frame()\n",
    "palC.columns=['Número de Críticas']\n",
    "\n",
    "\n",
    "\n",
    "palI=pd.DataFrame(data=palavras_separadas['Irrelevantes'])\n",
    "palI=palI[0].value_counts().to_frame()\n",
    "palI.columns=['Número de Irrelevantes']\n",
    "\n",
    "\n",
    "pal=palE.join(palC, how='outer').fillna(0)\n",
    "pal=pal.join(palI, how='outer').fillna(0)\n",
    "pal.sort_values(by='Número de Irrelevantes', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificar(tweet):\n",
    "    PE=pal['Número de Elogios']\n",
    "    somaE=sum(PE)\n",
    "    probE=1\n",
    "    PC=pal['Número de Críticas']\n",
    "    somaC=sum(PC)\n",
    "    probC=1\n",
    "    PI=pal['Número de Irrelevantes']\n",
    "    somaI=sum(PI)\n",
    "    probI=1\n",
    "    tot=len(pal)\n",
    "    \n",
    "    for palavra in limpador(tweet):\n",
    "        if palavra in pal.index:\n",
    "            probE*=((PE[i]+1)/(somaE+tot)) #ou eu divido por somaE +soma C...., ou soh pelo total\n",
    "            probC*=((PC[i]+1)/(somaC+tot))\n",
    "            probI*=((PI[i]+1)/(somaI+tot))\n",
    "        else:\n",
    "            probE*=(1/(somaE+tot)) #ou soh por 1? ou tenq usar laplace\n",
    "            probC*=(1/(somaC+tot))\n",
    "            probI*=(1/(somaI+tot))\n",
    "            \n",
    "    probE*=(Elogios/Total)\n",
    "    probC*=(Críticas/Total)\n",
    "    probI*=(Irrelevantes/Total)\n",
    "    \n",
    "    probMax=0\n",
    "    resultado=0\n",
    "    \n",
    "    for e in [probE,probC,probI]:\n",
    "        if e==probE:\n",
    "            a='Elogio'\n",
    "        if e==probC:\n",
    "            a='Crítica'\n",
    "        if e==probI:\n",
    "            a='Irrelevante'\n",
    "        if e>probMax:\n",
    "            probMax=e\n",
    "            resultado=a\n",
    "        \n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tirar os retweets denovo, mas p/ testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
