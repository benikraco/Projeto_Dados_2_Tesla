{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Amanda Ades\n",
    "\n",
    "Nome: Beni Kracochansky\n",
    "\n",
    "Nome: Gabriel Kabbani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, gostariamos de explicitar que durante a nossa análise, os números \"0,1,2\" representam, respectivamente, elogios, críticas, e irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Tesla'\n",
    "\n",
    "#aumentamos a quantidade de mensagens devido a quantidade de retweets.\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 950\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 600\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets= pd.ExcelFile('Tesla.xlsx')\n",
    "treino= pd.read_excel(tweets, sheet_name='Treinamento')\n",
    "teste= pd.read_excel(tweets, sheet_name='Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando a base de dados:\n",
    "\n",
    "def limpador(tweet):\n",
    "    retirar=[',',';','\\n','...','......','***','.','-','|','?','!',':','[',']','(',')','\"',\"'\",'&','#'] #verificar se faltam outros.\n",
    "    tweet=str(tweet)\n",
    "    tweet=tweet.split()\n",
    "    lista=['@','https://']\n",
    "    for i in tweet:\n",
    "        i=i.lower()\n",
    "    palavras=[]\n",
    "    for palavra in tweet:\n",
    "        if len(palavra)>0:\n",
    "            if palavra[0]==lista[0]:\n",
    "                pass\n",
    "            if len(palavra)>7:\n",
    "                if palavra[:8]==lista[1]:\n",
    "                    pass\n",
    "            else:\n",
    "                for item in retirar:\n",
    "                    palavra=palavra.strip(item)\n",
    "                palavras.append(palavra)\n",
    "    return \" \".join(palavras)\n",
    "\n",
    "tweets=[]\n",
    "for tweet in treino['Treinamento']: #limpando todos os tweets da sheet 'Treinamento', e adicionando eles a uma lista.\n",
    "        tweets.append(limpador(tweet))\n",
    "for e in range (len(treino['Treinamento'])): #limpa o dataframe com os dados obtidos acima.\n",
    "    if tweets[e][:2] == \"rt\": #removendo retweets.\n",
    "        treino['Classificacao'][e]=3 #colocando um número diferente para que os retweets não sejam utilizados na analise. Destes, os @ não serão retirados, mas isso não impacta a análise pois não serão utilizados nela.\n",
    "    else:\n",
    "        treino['Treinamento'][e]=tweets[e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Elogios,Críticas,Irrelevantes,Retweets=treino['Classificacao'].value_counts()\n",
    "Total=Elogios+Críticas+Irrelevantes\n",
    "\n",
    "print('Total de elogios: {0}\\nTotal de críticas: {1}\\nTotal de irrelevantes: {2}\\nTotal: {3}'.format(Elogios,Críticas,Irrelevantes,Total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E=treino[treino['Classificacao']==0]\n",
    "C=treino[treino['Classificacao']==1]\n",
    "I=treino[treino['Classificacao']==2]\n",
    "palavras_separadas={}\n",
    "i=0\n",
    "\n",
    "for tipo in [E,C,I]: #separa as palavras de cada tipo de classificação em uma lista. Essa lista será o valor do nome do tipo de classificação no dicionário.\n",
    "    if i==0:\n",
    "        nome='Elogios'\n",
    "    if i==1:\n",
    "        nome='Críticas'\n",
    "    if i==2:\n",
    "        nome='Irrelevantes'\n",
    "    lista=[]\n",
    "    for tweet in tipo['Treinamento']:\n",
    "        palavras=tweet.split()\n",
    "        lista.extend(palavras)\n",
    "    palavras_separadas[nome]=lista\n",
    "    i+=1\n",
    "\n",
    "\n",
    "palE=pd.DataFrame(data=palavras_separadas['Elogios'])\n",
    "palE=palE[0].value_counts().to_frame()\n",
    "palE.columns=['Número de Elogios']\n",
    "\n",
    "\n",
    "palC=pd.DataFrame(data=palavras_separadas['Críticas'])\n",
    "palC=palC[0].value_counts().to_frame()\n",
    "palC.columns=['Número de Críticas']\n",
    "\n",
    "\n",
    "\n",
    "palI=pd.DataFrame(data=palavras_separadas['Irrelevantes'])\n",
    "palI=palI[0].value_counts().to_frame()\n",
    "palI.columns=['Número de Irrelevantes']\n",
    "\n",
    "\n",
    "pal=palE.join(palC, how='outer').fillna(0)\n",
    "pal=pal.join(palI, how='outer').fillna(0)\n",
    "pal.sort_values(by='Número de Irrelevantes', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador(tweet):\n",
    "    PE=pal['Número de Elogios']\n",
    "    somaE=sum(PE)\n",
    "    probE=1\n",
    "    PC=pal['Número de Críticas']\n",
    "    somaC=sum(PC)\n",
    "    probC=1\n",
    "    PI=pal['Número de Irrelevantes']\n",
    "    somaI=sum(PI)\n",
    "    probI=1\n",
    "    tot=len(pal)\n",
    "    \n",
    "    for palavra in limpador(tweet):\n",
    "        if palavra in pal.index:\n",
    "            probE*=((PE[palavra]+1)/(somaE+tot)) #Laplace\n",
    "            probC*=((PC[palavra]+1)/(somaC+tot))\n",
    "            probI*=((PI[palavra]+1)/(somaI+tot))\n",
    "        else:\n",
    "            probE*=(1/(somaE+tot)) #Laplace\n",
    "            probC*=(1/(somaC+tot))\n",
    "            probI*=(1/(somaI+tot))\n",
    "            \n",
    "    probE*=(Elogios/Total)\n",
    "    probC*=(Críticas/Total)\n",
    "    probI*=(Irrelevantes/Total)\n",
    "    \n",
    "    probMax=0\n",
    "    resultado=0\n",
    "    \n",
    "    for e in [probE,probC,probI]:\n",
    "        if e==probE:\n",
    "            a='0'#elogio\n",
    "        if e==probC:\n",
    "            a='1'#critica\n",
    "        if e==probI:\n",
    "            a='2'#irrelevante\n",
    "        if e>probMax:\n",
    "            probMax=e\n",
    "            resultado=a\n",
    "        \n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste['Classificacao'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_elogio=0\n",
    "false_elogio=0\n",
    "true_critica=0\n",
    "false_critica=0\n",
    "true_irrelevante=0\n",
    "false_irrelevante=0\n",
    "\n",
    "for e in teste.index:\n",
    "    if int(classificador(limpador(teste['Teste'][e]))) == int(teste['Classificacao'][e]):\n",
    "        if int(teste['Classificacao'][e])==0:\n",
    "            true_elogio+=1\n",
    "        elif int(teste['Classificacao'][e])==1:\n",
    "            true_critica+=1\n",
    "        elif int(teste['Classificacao'][e])==2:\n",
    "            true_irrelevante+=1\n",
    "    elif int(classificador(limpador(teste['Teste'][e]))) != int(teste['Classificacao'][e]):\n",
    "        if int(classificador(teste['Teste'][e]))==0:\n",
    "            false_elogio+=1\n",
    "        elif int(classificador(teste['Teste'][e]))==1:\n",
    "            false_critica+=1\n",
    "        elif int(classificador(teste['Teste'][e]))==2:\n",
    "            false_irrelevante+=1\n",
    "            \n",
    "\n",
    "totale=true_elogio+false_elogio\n",
    "totalc=true_critica+false_critica\n",
    "totali=true_irrelevante+false_irrelevante\n",
    "\n",
    "FC=false_critica*100/totalc\n",
    "FE=false_elogio*100/totale\n",
    "FI=false_irrelevante*100/totali\n",
    "\n",
    "\n",
    "print(\"Elogio verdadeiro:\\nQuantidade:{0}\\nPorcentagem do total de elogios:{1:.2f}%\".format(true_elogio,true_elogio*100/totale))\n",
    "print()\n",
    "print()\n",
    "print(\"Elogio falso:\\nQuantidade:{0}\\nPorcentagem do total de elogios:{1:.2f}%\".format(false_elogio,FE))\n",
    "print()\n",
    "print()\n",
    "print(\"Crítica verdadeira:\\nQuantidade:{0}\\nPorcentagem do total de críticas:{1:.2f}%\".format(true_critica,true_critica*100/totalc))\n",
    "print()\n",
    "print()\n",
    "print(\"Crítica falsa:\\nQuantidade:{0}\\nPorcentagem do total de críticas:{1:.2f}%\".format(false_critica,FC))\n",
    "print()\n",
    "print()\n",
    "print(\"Irrelevante verdadeiro:\\nQuantidade:{0}\\nPorcentagem do total de irrelevantes:{1:.2f}%\".format(true_irrelevante,true_irrelevante*100/totali))\n",
    "print()\n",
    "print()\n",
    "print(\"Irrelevante falso:\\nQuantidade:{0}\\nPorcentagem do total de irrelevantes:{1:.2f}%\".format(false_irrelevante,FI))\n",
    "print()\n",
    "print('------------------------------------------------------')\n",
    "print()\n",
    "print(\"Porcentagem de erro do classificador: {0:.2f}%\".format(FE/3+FC/3+FI/3))\n",
    "print()\n",
    "print(\"Porcentagem de acerto do classificador: {0:.2f}%\".format(100-(FE/3+FC/3+FI/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)\n",
    "while (True):\n",
    "    produto = 'Tesla'\n",
    "    lang = 'pt'\n",
    "    n=200\n",
    "    i = 1\n",
    "    msgs = []\n",
    "    for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "    shuffle(msgs)\n",
    "\n",
    "\n",
    "    #Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "    live = pd.DataFrame({'Ao vivo' : pd.Series(msgs)})\n",
    "    lista=[]\n",
    "    for tweet in live['Ao vivo']:\n",
    "        lista.append(int(classificador(limpador(tweet))))\n",
    "    porcentagem_elogio=(lista.count(0))*100/len(lista)\n",
    "    porcentagem_critica=(lista.count(1))*100/len(lista)\n",
    "    porcentagem_irrelevante=(lista.count(2))*100/len(lista)\n",
    "    \n",
    "    print('Porcentagem de elogios, com relação ao total de tweets: {0:.2f}%'.format(porcentagem_elogio))\n",
    "    print('Porcentagem de criticas, com relação ao total de tweets: {0:.2f}%'.format(porcentagem_critica))\n",
    "    print('Porcentagem de irrelevantes, com relação ao total de tweets: {0:.2f}%'.format(porcentagem_irrelevante))\n",
    "    \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "    x = [porcentagem_elogio,porcentagem_critica, porcentagem_irrelevante]\n",
    "    bars = ('elogios', 'criticas', 'irrelevantes')\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.bar(y_pos, x)\n",
    "    plt.xticks(y_pos, bars)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    sleep(60**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criticar o \"nao gosto\" que vai ficar \"nao\" e \"gosto\", dificultando a analise e piorando o classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
